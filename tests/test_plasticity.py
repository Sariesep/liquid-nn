"""PlasticSynapse unit testleri."""

import sys, os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

import torch
import torch.nn.functional as F
from liquidnn import PlasticSynapse


def test_forward_shape():
    syn = PlasticSynapse(64, 32)
    x = torch.randn(4, 64)
    y = syn(x)
    assert y.shape == (4, 32), f"Beklenen (4,32), alÄ±nan {y.shape}"
    print("âœ… forward_shape")


def test_hebb_update():
    syn = PlasticSynapse(64, 32)
    x = torch.randn(4, 64)
    y = syn(x)
    assert syn.hebb_norm == 0.0, "Hebb baÅŸlangÄ±Ã§ta 0 olmalÄ±"

    syn.update_hebb(x, y)
    assert syn.hebb_norm > 0.0, "Hebb gÃ¼ncellemeden sonra > 0 olmalÄ±"
    print("âœ… hebb_update")


def test_hebb_reset():
    syn = PlasticSynapse(64, 32)
    x = torch.randn(4, 64)
    y = syn(x)
    syn.update_hebb(x, y)
    assert syn.hebb_norm > 0

    syn.reset_hebb()
    assert syn.Hebb is None, "Reset sonrasÄ± Hebb None olmalÄ±"
    print("âœ… hebb_reset")


def test_hebb_norm_bounded():
    """Hebb normu Ã¶ÄŸrenilebilir kapasiteyi aÅŸmamalÄ±."""
    syn = PlasticSynapse(64, 32)
    x = torch.randn(4, 64)
    for _ in range(100):
        y = syn(x)
        syn.update_hebb(x, y)

    max_allowed = F.softplus(syn.hebb_capacity).item()
    assert syn.hebb_norm <= max_allowed * 1.01, \
        f"Hebb norm {syn.hebb_norm:.4f} > limit {max_allowed:.4f}"
    print("âœ… hebb_norm_bounded")


def test_hebb_detach():
    syn = PlasticSynapse(64, 32)
    x = torch.randn(4, 64)
    y = syn(x)
    syn.update_hebb(x, y)
    old_norm = syn.hebb_norm

    syn.detach_hebb()
    assert abs(syn.hebb_norm - old_norm) < 1e-6, "Detach norm deÄŸiÅŸtirmemeli"
    assert not syn.Hebb.requires_grad, "Detach sonrasÄ± grad olmamalÄ±"
    print("âœ… hebb_detach")


if __name__ == "__main__":
    test_forward_shape()
    test_hebb_update()
    test_hebb_reset()
    test_hebb_norm_bounded()
    test_hebb_detach()
    print("\nðŸ† TÃ¼m plastisite testleri geÃ§ti!")
